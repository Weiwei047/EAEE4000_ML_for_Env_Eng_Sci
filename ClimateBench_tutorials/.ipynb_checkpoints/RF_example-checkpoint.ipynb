{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bfab689-07c4-4adb-b4d7-12de75e9c249",
   "metadata": {},
   "source": [
    "**This notebook introduces how to train a random forest model to predict the global temperature. <br/>**\n",
    "\n",
    "By Weiwei Zhan\n",
    "\n",
    "Reference: https://github.com/duncanwp/ClimateBench/blob/main/baseline_models/Original_RF_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b235f64-5789-4ca9-8514-518fcd5ad0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from utils import * \n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 400\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams[\"legend.frameon\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32fb634e-48c8-43a8-92d0-334edc3dd94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "train_path = os.path.join(cwd,'Data','train_val')\n",
    "test_path  = os.path.join(cwd,'Data','test')\n",
    "\n",
    "make_dir(train_path)\n",
    "make_dir(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b0697-1d63-4486-b98a-3eedbdd8dfc9",
   "metadata": {},
   "source": [
    "### 1. data preprocssing: prepare data for training & test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b67b5c-5214-409b-a73a-5531b4d82bc9",
   "metadata": {},
   "source": [
    "#### import data as training & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed020162-d240-4d1b-9936-3f6ce7af3a5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/Users/pg2328/Dropbox/Classes/ML_env_sci_eng/EAEE4000_ML_for_Env_Eng_Sci/ClimateBench_tutorials/train_val/inputs_historical.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/keras/lib/python3.10/site-packages/xarray/backends/file_manager.py:201\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keras/lib/python3.10/site-packages/xarray/backends/lru_cache.py:55\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 55\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/Users/pg2328/Dropbox/Classes/ML_env_sci_eng/EAEE4000_ML_for_Env_Eng_Sci/ClimateBench_tutorials/train_val/inputs_historical.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistorical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssp585\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssp126\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssp370\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhist-aer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhist-GHG\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m X_train_xr, X_length  \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m y_train_xr, y_length  \u001b[38;5;241m=\u001b[39m prepare_predictand(train_files,train_path)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Test set\u001b[39;00m\n",
      "File \u001b[0;32m~/Dropbox/Classes/ML_env_sci_eng/EAEE4000_ML_for_Env_Eng_Sci/ClimateBench_tutorials/utils.py:28\u001b[0m, in \u001b[0;36mprepare_predictor\u001b[0;34m(data_sets, data_path, time_reindex)\u001b[0m\n\u001b[1;32m     25\u001b[0m length_all \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m data_sets:\n\u001b[0;32m---> 28\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.nc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     X_all\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m     30\u001b[0m     length_all\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mtime))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keras/lib/python3.10/site-packages/xarray/backends/api.py:531\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    520\u001b[0m     decode_cf,\n\u001b[1;32m    521\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    528\u001b[0m )\n\u001b[1;32m    530\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 531\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    538\u001b[0m     backend_ds,\n\u001b[1;32m    539\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    548\u001b[0m )\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keras/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:555\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    536\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    552\u001b[0m ):\n\u001b[1;32m    554\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 555\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mNetCDF4DataStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keras/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:384\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    378\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    379\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    380\u001b[0m )\n\u001b[1;32m    381\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    382\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    383\u001b[0m )\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keras/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:332\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keras/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:393\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keras/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:387\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m    388\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keras/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keras/lib/python3.10/site-packages/xarray/backends/file_manager.py:189\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keras/lib/python3.10/site-packages/xarray/backends/file_manager.py:207\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    205\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    206\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 207\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2307\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:1925\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/Users/pg2328/Dropbox/Classes/ML_env_sci_eng/EAEE4000_ML_for_Env_Eng_Sci/ClimateBench_tutorials/train_val/inputs_historical.nc'"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "train_files = [\"historical\", \"ssp585\", \"ssp126\", \"ssp370\",\"hist-GHG\",\"hist-aer\"]\n",
    "X_train_xr, X_length  = prepare_predictor(train_files,train_path)\n",
    "y_train_xr, y_length  = prepare_predictand(train_files,train_path)\n",
    "\n",
    "# Test set\n",
    "X_test_xr, _ = prepare_predictor('ssp245', data_path=test_path,time_reindex=False)\n",
    "y_test_xr, _ = prepare_predictand('ssp245',data_path=test_path,time_reindex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed510c19-049d-4c61-88de-3d2945298cda",
   "metadata": {},
   "source": [
    "#### select relevant variables\n",
    "\n",
    "predictors: CO2 & CH4 <br/>\n",
    "predictand: tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb652830-5052-4750-8e7b-d5e47e76d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame({\"CO2\": X_train_xr[\"CO2\"].data,\n",
    "                           \"CH4\": X_train_xr[\"CH4\"].data\n",
    "                          }, index=X_train_xr[\"CO2\"].coords['time'].data)\n",
    "\n",
    "X_test_df  = pd.DataFrame({\"CO2\": X_test_xr[\"CO2\"].data,\n",
    "                           \"CH4\": X_test_xr[\"CH4\"].data\n",
    "                          }, index=X_test_xr[\"CO2\"].coords['time'].data)\n",
    "\n",
    "\n",
    "y_train_df = y_train_xr[\"tas\"].stack(dim=[\"latitude\", \"longitude\"])\n",
    "y_train_df = pd.DataFrame(y_train_df.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf99290-b863-4bb1-bc01-5570bbd1c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c6c438-ad0e-4f3f-b5f8-3c9ba3eeeeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35f072-b494-41b8-b154-98dfdad233ca",
   "metadata": {},
   "source": [
    "#### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76c3a9-3909-459d-a6aa-4494374b91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "mean, std = X_train_df.mean(), X_train_df.std()\n",
    "\n",
    "X_train_df   = (X_train_df - mean)/std\n",
    "X_test_df    = (X_test_df - mean)/std\n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "y_train = y_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d436e4a2-415c-492d-b0a9-13ebeb9ec024",
   "metadata": {},
   "source": [
    "### 2. Build & train the RF model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d92f8ed-165d-4faa-87f1-14a6cdc40ea6",
   "metadata": {},
   "source": [
    "We are using **cross validation** to find the optimum hyperparameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6b4b6-6179-4f47-9caa-b402a4564f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSCV = True # whether to do cross validation \n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300, num = 5)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5,55, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10, 15, 25]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [4, 8, 12,16]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53d39d-530e-4669-9ffa-02290037fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c85b99-5543-4354-90bf-a428b0c0436e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg0 = RandomForestRegressor(random_state=0)\n",
    "\n",
    "if(RSCV==False): # No cross validation\n",
    "    rf_tas = reg0.fit(X_train,y_train)\n",
    "    \n",
    "else: # perform cross validation\n",
    "    rf_random0 = RandomizedSearchCV(estimator = reg0, param_distributions = random_grid, \n",
    "                                    n_iter = 5, cv = 3, verbose=2, n_jobs = -1)\n",
    "    rf_tas = rf_random0.fit(X_train,y_train)\n",
    "    \n",
    "if(RSCV==True): \n",
    "    print(\"The best hyperparameters: \\n\",rf_tas.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6f7f5-80c1-4c60-a6c2-dbd3784316fc",
   "metadata": {},
   "source": [
    "### 3. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da11f08-7a3c-412b-93c6-c631f9b98d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pre = rf_tas.predict(X_test)\n",
    "y_test_pre = y_test_pre.reshape(y_test_pre.shape[0], 96, 144)\n",
    "\n",
    "y_test_pre = xr.Dataset(coords={'time': X_test_xr.time.values, \n",
    "                               'latitude': X_test_xr.latitude.values, \n",
    "                               'longitude': X_test_xr.longitude.values},\n",
    "                        data_vars=dict(tas=(['time', 'latitude', 'longitude'], y_test_pre)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0deb1d9-63c1-40bf-81cf-e8e66a076de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15,12),ncols=2,nrows=3)\n",
    "\n",
    "yrs = [2030, 2050, 2100]\n",
    "vmin, vmax    = -6, 6\n",
    "cmap = 'RdBu_r'\n",
    "y_test_pre.tas.sel(time=yrs[0]).plot(ax=axes[0,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[0]).plot(ax=axes[0,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "y_test_pre.tas.sel(time=yrs[1]).plot(ax=axes[1,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[1]).plot(ax=axes[1,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "y_test_pre.tas.sel(time=yrs[2]).plot(ax=axes[2,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[2]).plot(ax=axes[2,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # left column: model prediction\n",
    "    if i % 2 == 0:\n",
    "        ax.set_title(f'tas model prediction (year = {yrs[i//2]})',fontweight='bold')\n",
    "    # right column: truth tas from ssp245 simulations\n",
    "    else:\n",
    "        ax.set_title(f'tas truth (year = {yrs[i//2]})',fontweight='bold')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed793a50-cba6-423b-88a1-bcc0f1dd2ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a9d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3d650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bafb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
